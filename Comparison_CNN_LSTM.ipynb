{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from pyDeepInsight import ImageTransformer, LogScaler\n",
    "from image_transformer import ImageTransformer, LogScaler\n",
    "\n",
    "import numpy as np\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import metrics\n",
    "import time\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop GPU cuda, to avoid cuda error imcomatibale between keras library and cuda nn\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8346, 12) (3577, 12)\n"
     ]
    }
   ],
   "source": [
    "# load dataset\n",
    "x_train=np.load(\"X_train.npy\")\n",
    "    \n",
    "scaler=StandardScaler()\n",
    "scaler.fit(x_train)\n",
    "x_train=scaler.transform(x_train)\n",
    "#===\n",
    "y_train=np.load(\"y_train.npy\")\n",
    "\n",
    "# -------------------------------------\n",
    "\n",
    "x_test=np.load(\"X_test.npy\")\n",
    "\n",
    "#====z_score normalization\n",
    "scaler2=StandardScaler()\n",
    "scaler2.fit(x_test)\n",
    "x_test=scaler2.transform(x_test)\n",
    "#====\n",
    "y_test=np.load(\"y_test.npy\")\n",
    "\n",
    "print(x_train.shape, x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11923, 12)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data_train=np.concatenate((x_train, x_test), axis= 0)\n",
    "all_data_y=np.concatenate((y_train, y_test), axis= 0)\n",
    "all_data_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1=time.time()\n",
    "\n",
    "# normalize data\n",
    "ln = LogScaler()\n",
    "all_data_train=ln.fit_transform(all_data_train)\n",
    "#x_test=ln.fit_transform(x_test)\n",
    "#all_data_train1=all_data_train[:50000,]\n",
    "#all_data_train2=all_data_train[:50000,]\n",
    "\n",
    "# transform data to image form towork in CNN\n",
    "it = ImageTransformer(feature_extractor='tsne', \n",
    "                      pixels=30, random_state=1701, \n",
    "                      n_jobs=-1)\n",
    "\n",
    "#all_data_train1 = it.fit_transform(all_data_train1)\n",
    "all_data_train = it.fit_transform(all_data_train)\n",
    "#x_test = it.fit_transform(x_test)\n",
    "#print(all_data_train1.shape, all_data_train2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11923, 30, 30, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#all_data_train=np.concatenate((all_data_train1, all_data_train2), axis=0)\n",
    "all_data_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9538, 30, 30, 3) (2385, 30, 30, 3)\n",
      "(9538,) (2385,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    all_data_train, all_data_y, test_size=0.20, random_state=42)\n",
    "print(X_train.shape, X_test.shape)\n",
    "print(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the convolutional base\n",
    "input_shape=X_train[0].shape\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 28, 28, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 12, 12, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 6, 6, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 4, 4, 32)          9248      \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (None, 4, 128)            0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 64)                49408     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 70,913\n",
      "Trainable params: 70,913\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Add Dense layers on top\n",
    "model.add(layers.TimeDistributed(layers.Flatten()))\n",
    "#TimeDistributed to prepare layr structure to be compatiable with LSTM\n",
    "\n",
    "# define LSTM model\n",
    "\n",
    "model.add(layers.LSTM(64, activation='relu'))\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "38/38 [==============================] - 10s 175ms/step - loss: 0.3519 - accuracy: 0.8879\n",
      "Epoch 2/20\n",
      "38/38 [==============================] - 4s 110ms/step - loss: 0.0778 - accuracy: 0.9165\n",
      "Epoch 3/20\n",
      "38/38 [==============================] - 4s 109ms/step - loss: 0.0526 - accuracy: 1.0000\n",
      "Epoch 4/20\n",
      "38/38 [==============================] - 4s 114ms/step - loss: 0.0059 - accuracy: 1.0000\n",
      "Epoch 5/20\n",
      "38/38 [==============================] - 5s 120ms/step - loss: 8.2899e-10 - accuracy: 1.0000\n",
      "Epoch 6/20\n",
      "38/38 [==============================] - 5s 132ms/step - loss: 4.5822e-10 - accuracy: 1.0000\n",
      "Epoch 7/20\n",
      "38/38 [==============================] - 6s 153ms/step - loss: 4.5435e-10 - accuracy: 1.0000\n",
      "Epoch 8/20\n",
      "38/38 [==============================] - 5s 137ms/step - loss: 4.5406e-10 - accuracy: 1.0000\n",
      "Epoch 9/20\n",
      "38/38 [==============================] - 5s 133ms/step - loss: 4.5384e-10 - accuracy: 1.0000\n",
      "Epoch 10/20\n",
      "38/38 [==============================] - 5s 135ms/step - loss: 4.5359e-10 - accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "38/38 [==============================] - 5s 134ms/step - loss: 4.5333e-10 - accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "38/38 [==============================] - 5s 134ms/step - loss: 4.5305e-10 - accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "38/38 [==============================] - 5s 134ms/step - loss: 4.5276e-10 - accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "38/38 [==============================] - 5s 141ms/step - loss: 4.5244e-10 - accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "38/38 [==============================] - 6s 145ms/step - loss: 4.5211e-10 - accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "38/38 [==============================] - 5s 137ms/step - loss: 4.5176e-10 - accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "38/38 [==============================] - 5s 139ms/step - loss: 4.5138e-10 - accuracy: 1.0000\n",
      "Epoch 18/20\n",
      " 1/38 [..............................] - ETA: 6s - loss: 2.1493e-10 - accuracy: 1.0000"
     ]
    }
   ],
   "source": [
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# fit the keras model on the dataset\n",
    "model.fit(X_train, y_train, epochs=20, batch_size=256)\n",
    "# evaluate the keras model\n",
    "_, accuracy = model.evaluate(X_train, y_train)\n",
    "print('Accuracy training : %.2f' % (accuracy*100))\n",
    "\n",
    "t2=time.time()\n",
    "\n",
    "print (\"time consumption : \", t2-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#yhat_classes = model.predict_classes(X_test, verbose=0)\n",
    "yhat_classes = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "\n",
    "#conf_matrix = confusion_matrix(y_true=y_test, y_pred=dt_pred)\n",
    "print('Precision: %.3f' % precision_score(y_test, yhat_classes))\n",
    "print('Recall: %.3f' % recall_score(y_test, yhat_classes))\n",
    "print('F1 Score: %.3f' % f1_score(y_test, yhat_classes))\n",
    "print('Accuracy: %.3f' % accuracy_score(y_test, yhat_classes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
